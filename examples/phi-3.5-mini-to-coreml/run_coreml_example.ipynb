{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch version 2.4.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.3.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "model = ct.models.MLModel(\"phi-3.5-mini-instruct-fp32.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "\n",
    "model_path = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "test_inputs = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\")\n",
    "\n",
    "coreml_inputs = {\"inputIds\": test_inputs.input_ids.to(torch.int32).numpy(),\n",
    "                 \"attentionMask\": test_inputs.attention_mask.to(torch.int32).numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "loc(\"/U"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': array([[[19.625   , 19.6875  , 23.90625 , ..., 23.484375, 23.484375,\n",
      "         23.484375],\n",
      "        [35.28125 , 39.59375 , 40.03125 , ..., 34.65625 , 34.65625 ,\n",
      "         34.65625 ],\n",
      "        [34.875   , 36.09375 , 34.75    , ..., 31.171875, 31.171875,\n",
      "         31.171875],\n",
      "        [34.6875  , 35.875   , 37.9375  , ..., 30.65625 , 30.65625 ,\n",
      "         30.65625 ],\n",
      "        [36.75    , 37.65625 , 40.1875  , ..., 31.15625 , 31.15625 ,\n",
      "         31.15625 ],\n",
      "        [39.40625 , 46.09375 , 46.875   , ..., 35.03125 , 35.03125 ,\n",
      "         35.03125 ]]], dtype=float32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sers/sanguk/Library/Caches/python/com.apple.e5rt.e5bundlecache/24A335/6061501E36529F5F2829324416D980299EC9DA3170FEA3C1C6638759251CA07D/B275CFBCA86171F2C9D7F45BADD50A6407DA90FE1AD2BC215609A0A055AEB12A.bundle/H13G.bundle/main/main_mps_graph/main_mps_graph.mpsgraphpackage/model_0.mpsgraph\":0:0): error: attempting to parse a byte at the end of the bytecode\n",
      "loc(\"/Users/sanguk/Library/Caches/python/com.apple.e5rt.e5bundlecache/24A335/6061501E36529F5F2829324416D980299EC9DA3170FEA3C1C6638759251CA07D/B275CFBCA86171F2C9D7F45BADD50A6407DA90FE1AD2BC215609A0A055AEB12A.bundle/H13G.bundle/main/main_mps_graph/main_mps_graph.mpsgraphpackage/model_0.mpsgraph\":0:0): error: attempting to parse a byte at the end of the bytecode\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(coreml_inputs)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[19.625    19.6875   23.90625  ... 23.484375 23.484375 23.484375]\n",
      "  [35.28125  39.59375  40.03125  ... 34.65625  34.65625  34.65625 ]\n",
      "  [34.875    36.09375  34.75     ... 31.171875 31.171875 31.171875]\n",
      "  [34.6875   35.875    37.9375   ... 30.65625  30.65625  30.65625 ]\n",
      "  [36.75     37.65625  40.1875   ... 31.15625  31.15625  31.15625 ]\n",
      "  [39.40625  46.09375  46.875    ... 35.03125  35.03125  35.03125 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[\"logits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latched",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
